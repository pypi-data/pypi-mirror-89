{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import cloudknot as ck\n",
    "import numpy as np\n",
    "import pandas as pd # for pd.to_datetime and the timedelta type\n",
    "import pickle # to save results\n",
    "\n",
    "from datetime import datetime\n",
    "from time import sleep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_heateq_2d(t_top=100.0, t_bottom=0.0,\n",
    "                    t_left=0.0, t_right=0.0, side_len=10,\n",
    "                    max_iter=10000, rtol=1e-4, atol=1e-7):\n",
    "    \"\"\"Solve steady-state 2D heat equation by Gauss-Seidel Method\n",
    "    \n",
    "    This is a pedagogical or benchmarking tool only. There are\n",
    "    better ways to solve the 2D heat equation if that's all you\n",
    "    want. There are even better ways to implement Gauss-Seidel.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    max_iter : int, default=10000\n",
    "        Maximum iteration number for Gauss-Seidel Method\n",
    "        \n",
    "    t_top : float, default=100.0\n",
    "        Dirichlet boundary condition for the top of the plate\n",
    "\n",
    "    t_bottom : float, default=0.0\n",
    "        Dirichlet boundary condition for the bottom of the plate\n",
    "    \n",
    "    t_left : float, default=0.0\n",
    "        Dirichlet boundary condition for the left of the plate\n",
    "    \n",
    "    t_right : float, default=0.0\n",
    "        Dirichlet boundary condition for the right of the plate\n",
    "\n",
    "    side_len : int, default=10\n",
    "        Number of points on one side of the 2D grid\n",
    "        \n",
    "    rtol : float, default=1e-4\n",
    "        Relative convergence tolerence for early exit of Gauss-Seidel loop\n",
    "\n",
    "    atol : float, default=1e-7\n",
    "        Absolute convergence tolerence for early exit of Gauss-Seidel loop\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    collections.namedtuple\n",
    "        namedtuple with elements\n",
    "        temp - final temperature\n",
    "        iteration - convergence iteration number\n",
    "            (or max_iter if convergence not reached)\n",
    "    \"\"\"\n",
    "    import numpy as np\n",
    "    \n",
    "    # Initial guess of interior grid\n",
    "    t_init = np.mean([t_top, t_bottom, t_left, t_right])\n",
    "\n",
    "    # Create grid of temps\n",
    "    t = np.ones((side_len, side_len), dtype=np.float64) * t_init\n",
    "\n",
    "    # Set Boundary condition\n",
    "    t[-1, :] = t_top\n",
    "    t[0, :] = t_bottom\n",
    "    t[:, -1] = t_right\n",
    "    t[:, 0] = t_left\n",
    "    \n",
    "    # Gauss-Seidel Loop\n",
    "    t_old = np.copy(t)\n",
    "    for iteration in range(0, max_iter):\n",
    "        for i in range(1, side_len-1):\n",
    "            for j in range(1, side_len-1):\n",
    "                t[i, j] = 0.25 * (t[i+1][j] + t[i-1][j] + t[i][j+1] + t[i][j-1])\n",
    "\n",
    "        if np.allclose(t, t_old):\n",
    "            break\n",
    "        else:\n",
    "            t_old = np.copy(t)\n",
    "    \n",
    "    return {'temperature': t, 'iteration': iteration}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:cloudknot.aws.batch:min_vcpus is greater than zero. This means that your compute environment will maintain some EC2 vCPUs, regardless of job demand, potentially resulting in unnecessary AWS charges. We strongly recommend using a compute environment with min_vcpus set to zero.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First time Knot initialization time:  0:00:33.452684\n"
     ]
    }
   ],
   "source": [
    "t_start = datetime.now()\n",
    "knot = ck.Knot(\n",
    "    name='test-heat-eq',\n",
    "    func=solve_heateq_2d,\n",
    "    min_vcpus=512,\n",
    "    desired_vcpus=2048,\n",
    "    max_vcpus=4096\n",
    ")\n",
    "t_stop = datetime.now()\n",
    "print('First time Knot initialization time: ', t_stop - t_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:cloudknot.cloudknot:You specified configuration arguments for a knot that already exists. Cloudknot has returned the pre-existing knot, ignoring all of your other input parameters, which may or may not be the same. You should proceed with caution and confirm that this knot's parameters are as expected. If you want to be extra-safe, choose a different name or clobber this pre-existing knot and instantiate a new one with your input arguments.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subsequent Knot initialization time:  0:00:02.530435\n"
     ]
    }
   ],
   "source": [
    "t_start = datetime.now()\n",
    "knot = ck.Knot(\n",
    "    name='test-heat-eq',\n",
    "    func=solve_heateq_2d,\n",
    "    min_vcpus=512,\n",
    "    desired_vcpus=2048,\n",
    "    max_vcpus=4096\n",
    ")\n",
    "t_stop = datetime.now()\n",
    "print('Subsequent Knot initialization time: ', t_stop - t_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "npoints = 2\n",
      "npoints = 4\n",
      "npoints = 8\n",
      "npoints = 16\n",
      "npoints = 32\n",
      "npoints = 64\n",
      "npoints = 128\n",
      "npoints = 256\n",
      "npoints = 512\n",
      "npoints = 1024\n",
      "npoints = 2048\n",
      "npoints = 4096\n"
     ]
    }
   ],
   "source": [
    "futures = {}\n",
    "for npoints in np.power(2, np.arange(1, 13)):\n",
    "    print('npoints = {npoints:d}'.format(npoints=int(npoints)))\n",
    "    # arg tuples are (t_top, t_bottom, t_left, t_right, side_len, max_iter, rtol, atol)\n",
    "    args = [(t, 0.0, 0.0, 0.0, 10, 10000, 1e-4, 1e-7) for t in np.linspace(0, 100, int(npoints))]\n",
    "    f = knot.map(args, starmap=True)\n",
    "    futures[npoints] = f\n",
    "    f.result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = boto3.client('batch', region_name='us-east-2')\n",
    "def get_job_time(parent_job_id):\n",
    "    parent_job = batch.describe_jobs(jobs=[parent_job_id])\n",
    "    job_size = parent_job['jobs'][0]['arrayProperties']['size']\n",
    "    start_time = pd.to_datetime(parent_job['jobs'][0]['createdAt'], unit='ms')\n",
    "    stop_times = []\n",
    "    for i in range(job_size):\n",
    "        child_job_id = parent_job_id + ':{i:d}'.format(i=i)\n",
    "        child_job = batch.describe_jobs(jobs=[child_job_id])\n",
    "        stop_times.append(child_job['jobs'][0]['stoppedAt'])\n",
    "    \n",
    "    stop_times = pd.to_datetime(stop_times, unit='ms')\n",
    "    max_delta = (stop_times - start_time).max()\n",
    "    return max_delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<cloudknot.aws.batch.BatchJob at 0x10e08db00>,\n",
       " <cloudknot.aws.batch.BatchJob at 0x109fb0208>,\n",
       " <cloudknot.aws.batch.BatchJob at 0x10ec8b780>,\n",
       " <cloudknot.aws.batch.BatchJob at 0x10a1426a0>,\n",
       " <cloudknot.aws.batch.BatchJob at 0x10a2f0898>,\n",
       " <cloudknot.aws.batch.BatchJob at 0x10a4242b0>,\n",
       " <cloudknot.aws.batch.BatchJob at 0x10e291748>,\n",
       " <cloudknot.aws.batch.BatchJob at 0x10f2535f8>,\n",
       " <cloudknot.aws.batch.BatchJob at 0x10e2a6438>,\n",
       " <cloudknot.aws.batch.BatchJob at 0x107c97b00>,\n",
       " <cloudknot.aws.batch.BatchJob at 0x10e451dd8>,\n",
       " <cloudknot.aws.batch.BatchJob at 0x10df50ba8>]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knot.jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_knot_job_ids = [job.job_id for job in knot.jobs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "exec_times = [get_job_time(jid) for jid in default_knot_job_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'max_job_time': Timedelta('0 days 00:01:02.008000'), 'npoints': 2},\n",
       " {'max_job_time': Timedelta('0 days 00:00:45.058000'), 'npoints': 4},\n",
       " {'max_job_time': Timedelta('0 days 00:00:43.976000'), 'npoints': 8},\n",
       " {'max_job_time': Timedelta('0 days 00:00:26.312000'), 'npoints': 16},\n",
       " {'max_job_time': Timedelta('0 days 00:00:23.610000'), 'npoints': 32},\n",
       " {'max_job_time': Timedelta('0 days 00:00:30.847000'), 'npoints': 64},\n",
       " {'max_job_time': Timedelta('0 days 00:00:43.013000'), 'npoints': 128},\n",
       " {'max_job_time': Timedelta('0 days 00:01:16.391000'), 'npoints': 256},\n",
       " {'max_job_time': Timedelta('0 days 00:02:09.463000'), 'npoints': 512},\n",
       " {'max_job_time': Timedelta('0 days 00:03:42.536000'), 'npoints': 1024},\n",
       " {'max_job_time': Timedelta('0 days 00:06:42.347000'), 'npoints': 2048},\n",
       " {'max_job_time': Timedelta('0 days 00:11:02.090000'), 'npoints': 4096}]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cloudknot_nargs_scaling = []\n",
    "for npoints, exec_time in zip(np.power(2, np.arange(1, 13)), exec_times):\n",
    "    cloudknot_nargs_scaling.append({\n",
    "        'npoints': npoints,\n",
    "        'max_job_time': exec_time\n",
    "    })\n",
    "cloudknot_nargs_scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('cloudknot_nargs_scaling.pkl', 'wb') as fp:\n",
    "    pickle.dump(cloudknot_nargs_scaling, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "side_lens = np.array([10, 25, 50, 100, 125, 150, 175])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "side_len = 10\n",
      "side_len = 25\n",
      "side_len = 50\n",
      "side_len = 100\n",
      "side_len = 125\n",
      "side_len = 150\n",
      "side_len = 175\n"
     ]
    }
   ],
   "source": [
    "futures = {}\n",
    "for side_len in side_lens:\n",
    "    print('side_len = {sl:d}'.format(sl=int(side_len)))\n",
    "    # arg tuples are (t_top, t_bottom, t_left, t_right, side_len, max_iter, rtol, atol)\n",
    "    args = [(t, 0.0, 0.0, 0.0, side_len, 10000, 1e-4, 1e-7) for t in np.linspace(0, 100, 5)]\n",
    "    f = knot.map(args, starmap=True)\n",
    "    futures[side_len] = f\n",
    "    f.result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'max_job_time': Timedelta('0 days 00:00:54.345000'), 'side_len': 10},\n",
       " {'max_job_time': Timedelta('0 days 00:00:30.709000'), 'side_len': 25},\n",
       " {'max_job_time': Timedelta('0 days 00:00:37.784000'), 'side_len': 50},\n",
       " {'max_job_time': Timedelta('0 days 00:01:12.454000'), 'side_len': 100},\n",
       " {'max_job_time': Timedelta('0 days 00:02:09.751000'), 'side_len': 125},\n",
       " {'max_job_time': Timedelta('0 days 00:03:43.170000'), 'side_len': 150},\n",
       " {'max_job_time': Timedelta('0 days 00:06:40.223000'), 'side_len': 175}]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "default_knot_job_ids = [job.job_id for job in knot.jobs[12:]]\n",
    "exec_times = [get_job_time(jid) for jid in default_knot_job_ids]\n",
    "\n",
    "cloudknot_syssize_scaling = []\n",
    "for side_len, exec_time in zip(side_lens, exec_times):\n",
    "    cloudknot_syssize_scaling.append({\n",
    "        'side_len': side_len,\n",
    "        'max_job_time': exec_time\n",
    "    })\n",
    "cloudknot_syssize_scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('cloudknot_syssize_scaling.pkl', 'wb') as fp:\n",
    "    pickle.dump(cloudknot_syssize_scaling, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:cloudknot.aws.ec2:Deleted dependent EC2 instances: ['i-055b4ecbdf88e257f']\n"
     ]
    }
   ],
   "source": [
    "knot.clobber(clobber_pars=True, clobber_repo=True, clobber_image=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (cloudknot-dev)",
   "language": "python",
   "name": "cloudknot-dev"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
