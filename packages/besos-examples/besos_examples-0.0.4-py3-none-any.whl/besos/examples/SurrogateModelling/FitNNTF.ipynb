{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.013224,
     "end_time": "2019-10-28T22:52:08.684601",
     "exception": false,
     "start_time": "2019-10-28T22:52:08.671377",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Tensorflow graph construction and training on building simulation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2,
    "papermill": {
     "duration": 2.181307,
     "end_time": "2019-10-28T22:52:10.877798",
     "exception": false,
     "start_time": "2019-10-28T22:52:08.696491",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from besos import eppy_funcs as ef, sampling\n",
    "from besos.evaluator import EvaluatorEP\n",
    "from besos.problem import EPProblem\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.compat import v1 as tf\n",
    "\n",
    "from parameter_sets import parameter_set\n",
    "\n",
    "\n",
    "tf.disable_v2_behavior()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.014435,
     "end_time": "2019-10-28T22:52:10.904812",
     "exception": false,
     "start_time": "2019-10-28T22:52:10.890377",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Generate data set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.011179,
     "end_time": "2019-10-28T22:52:10.927649",
     "exception": false,
     "start_time": "2019-10-28T22:52:10.916470",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "This generates an example model and sampling data, see [this example](FitGPModel.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 34.436534,
     "end_time": "2019-10-28T22:52:45.375705",
     "exception": false,
     "start_time": "2019-10-28T22:52:10.939171",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "parameters = parameter_set(7)\n",
    "problem = EPProblem(parameters, [\"Electricity:Facility\"])\n",
    "building = ef.get_building()\n",
    "inputs = sampling.dist_sampler(sampling.lhs, problem, 30)\n",
    "evaluator = EvaluatorEP(problem, building)\n",
    "outputs = evaluator.df_apply(inputs)\n",
    "results = inputs.join(outputs)\n",
    "results.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.013758,
     "end_time": "2019-10-28T22:52:45.402371",
     "exception": false,
     "start_time": "2019-10-28T22:52:45.388613",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Tensorflow Feed-forward Neural Network Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.01219,
     "end_time": "2019-10-28T22:52:45.427894",
     "exception": false,
     "start_time": "2019-10-28T22:52:45.415704",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### 1) Define Network Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.012496,
     "end_time": "2019-10-28T22:52:45.453218",
     "exception": false,
     "start_time": "2019-10-28T22:52:45.440722",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Static Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.011871,
     "end_time": "2019-10-28T22:52:45.477535",
     "exception": false,
     "start_time": "2019-10-28T22:52:45.465664",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "All network parameters defined in this section are not part of the hyperparameter optimisation.\n",
    "Any of these parameters can be switched to an optimization parameter (see below)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.018869,
     "end_time": "2019-10-28T22:52:45.509710",
     "exception": false,
     "start_time": "2019-10-28T22:52:45.490841",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.1\n",
    "training_epochs = 4000\n",
    "display_step = 300\n",
    "\n",
    "n_hidden_1 = 10\n",
    "n_hidden_2 = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.012681,
     "end_time": "2019-10-28T22:52:45.536106",
     "exception": false,
     "start_time": "2019-10-28T22:52:45.523425",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Hyper-parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.012245,
     "end_time": "2019-10-28T22:52:45.560760",
     "exception": false,
     "start_time": "2019-10-28T22:52:45.548515",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Here we use the L2 norm regularization parameter alpha to calibrate the network bias-variance trade-off."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.0188,
     "end_time": "2019-10-28T22:52:45.591749",
     "exception": false,
     "start_time": "2019-10-28T22:52:45.572949",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "alpha = tf.placeholder(tf.float32, None, name=\"Alpha\")\n",
    "hy_par = [1e0, 1e1, 1e3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.014192,
     "end_time": "2019-10-28T22:52:45.619808",
     "exception": false,
     "start_time": "2019-10-28T22:52:45.605616",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### 2) Train-Test split, standardization\n",
    "Next we split the data into a training set (80%) and a testing set (20%), and normalise it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.024807,
     "end_time": "2019-10-28T22:52:45.659093",
     "exception": false,
     "start_time": "2019-10-28T22:52:45.634286",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_in, test_in, train_out, test_out = train_test_split(\n",
    "    inputs, outputs, test_size=0.2\n",
    ")\n",
    "scaler = StandardScaler()\n",
    "X_norm = scaler.fit_transform(X=train_in)\n",
    "X_norm_test = scaler.transform(test_in)\n",
    "\n",
    "scaler_out = StandardScaler()\n",
    "y_norm = scaler_out.fit_transform(X=train_out)\n",
    "y_norm_test = scaler_out.transform(test_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.01253,
     "end_time": "2019-10-28T22:52:45.684321",
     "exception": false,
     "start_time": "2019-10-28T22:52:45.671791",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 3) Set up the Tensorflow graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.012192,
     "end_time": "2019-10-28T22:52:45.708976",
     "exception": false,
     "start_time": "2019-10-28T22:52:45.696784",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Set up inputs and outputs as placeholder variables to be used in setting up the Tensorflow graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.022007,
     "end_time": "2019-10-28T22:52:45.744386",
     "exception": false,
     "start_time": "2019-10-28T22:52:45.722379",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, [None, len(X_norm[0, :])], name=\"X\")\n",
    "Y = tf.placeholder(tf.float32, [None, len(y_norm[0, :])], name=\"y\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.014847,
     "end_time": "2019-10-28T22:52:45.771932",
     "exception": false,
     "start_time": "2019-10-28T22:52:45.757085",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### 4) Define weight, bias terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.045084,
     "end_time": "2019-10-28T22:52:45.830825",
     "exception": false,
     "start_time": "2019-10-28T22:52:45.785741",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "with tf.name_scope(\"Variable_Definition\"):\n",
    "    weights = {\n",
    "        \"h1\": tf.Variable(\n",
    "            tf.random_normal([len(X_norm[0, :]), n_hidden_1]), name=\"HiddenLayer1\"\n",
    "        ),\n",
    "        \"h2\": tf.Variable(\n",
    "            tf.random_normal([n_hidden_1, n_hidden_2]), name=\"HiddenLayer2\"\n",
    "        ),\n",
    "        \"out\": tf.Variable(\n",
    "            tf.random_normal([n_hidden_2, len(y_norm[0, :])]), name=\"OutputLayer1\"\n",
    "        ),\n",
    "    }\n",
    "\n",
    "    biases = {\n",
    "        \"b1\": tf.Variable(tf.random_normal([n_hidden_1]), name=\"Bias\"),\n",
    "        \"b2\": tf.Variable(tf.random_normal([n_hidden_2]), name=\"Bias\"),\n",
    "        \"out\": tf.Variable(tf.random_normal([1])),\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.013002,
     "end_time": "2019-10-28T22:52:45.857752",
     "exception": false,
     "start_time": "2019-10-28T22:52:45.844750",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### 5) Define Inference Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.024022,
     "end_time": "2019-10-28T22:52:45.894959",
     "exception": false,
     "start_time": "2019-10-28T22:52:45.870937",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "with tf.name_scope(\"FFNN_Model\"):  # open up the Tensorflow name scope (context manager)\n",
    "\n",
    "    def multilayer_perceptron(\n",
    "        x,\n",
    "    ):  # this function defines the Graph of our neural network\n",
    "        with tf.name_scope(\"HL1\"):\n",
    "            layer_1 = tf.add(\n",
    "                tf.matmul(x, weights[\"h1\"]), biases[\"b1\"]\n",
    "            )  # apply Cartesian Product on inputs to the network (x) and the weights of layer 1, afterwards add the biases.\n",
    "            layer_1 = tf.nn.relu(\n",
    "                layer_1\n",
    "            )  # Apply the relu activation function subsequently in each of the neurons\n",
    "        with tf.name_scope(\"HL2\"):\n",
    "            layer_2 = tf.add(\n",
    "                tf.matmul(layer_1, weights[\"h2\"]), biases[\"b2\"]\n",
    "            )  # see above only we use layer_1 as input to layer_2\n",
    "            layer_2 = tf.nn.relu(layer_2)\n",
    "        with tf.name_scope(\"OutputLayer\"):\n",
    "            out_layer = tf.matmul(layer_2, weights[\"out\"]) + biases[\"out\"]\n",
    "        return out_layer\n",
    "\n",
    "    # 5b) Construct Model\n",
    "    y_pred = multilayer_perceptron(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.012118,
     "end_time": "2019-10-28T22:52:45.919867",
     "exception": false,
     "start_time": "2019-10-28T22:52:45.907749",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### 6) Define Loss function (operation definition), incl. L2 Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.023643,
     "end_time": "2019-10-28T22:52:45.955667",
     "exception": false,
     "start_time": "2019-10-28T22:52:45.932024",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "with tf.name_scope(\"Cost_regularized\"):  # next element in the TF-Graph\n",
    "    # set up mean squared error with L2 regularization\n",
    "    loss_op = tf.reduce_mean(tf.square(Y - y_pred)) + alpha * (\n",
    "        tf.nn.l2_loss(weights[\"h1\"])\n",
    "        + tf.nn.l2_loss(weights[\"h2\"])\n",
    "        + tf.nn.l2_loss(weights[\"out\"])\n",
    "    )\n",
    "    tf.summary.scalar(\"Test\", loss_op)  # observe the loss function throughout the run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.0122,
     "end_time": "2019-10-28T22:52:45.980935",
     "exception": false,
     "start_time": "2019-10-28T22:52:45.968735",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### 7) Define other metrics to be observed (not cost function)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.012588,
     "end_time": "2019-10-28T22:52:46.006747",
     "exception": false,
     "start_time": "2019-10-28T22:52:45.994159",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "R^2 score (operation definition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.025444,
     "end_time": "2019-10-28T22:52:46.044593",
     "exception": false,
     "start_time": "2019-10-28T22:52:46.019149",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "with tf.name_scope(\"R2_Score\"):\n",
    "    total_error = tf.reduce_sum(tf.square(Y - tf.reduce_mean(Y)))\n",
    "    unexplained_error = tf.reduce_sum(tf.square(Y - y_pred))\n",
    "    R_squared = tf.subtract(1.0, tf.div(unexplained_error, total_error))\n",
    "    tf.summary.scalar(\"R2\", R_squared)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.012067,
     "end_time": "2019-10-28T22:52:46.069462",
     "exception": false,
     "start_time": "2019-10-28T22:52:46.057395",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Mean Absolute Error (MAE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.022337,
     "end_time": "2019-10-28T22:52:46.105199",
     "exception": false,
     "start_time": "2019-10-28T22:52:46.082862",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "with tf.name_scope(\"MAE\"):\n",
    "    mae = tf.reduce_mean(tf.abs(Y - y_pred))\n",
    "    tf.summary.scalar(\"MAE\", loss_op)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.012488,
     "end_time": "2019-10-28T22:52:46.130833",
     "exception": false,
     "start_time": "2019-10-28T22:52:46.118345",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### 8) Define Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.116387,
     "end_time": "2019-10-28T22:52:46.259843",
     "exception": false,
     "start_time": "2019-10-28T22:52:46.143456",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "with tf.name_scope(\"Training\"):\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate, name=\"Training\")\n",
    "    train_op = optimizer.minimize(loss_op)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.012446,
     "end_time": "2019-10-28T22:52:46.286030",
     "exception": false,
     "start_time": "2019-10-28T22:52:46.273584",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### 9) Define Variable initializer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.01854,
     "end_time": "2019-10-28T22:52:46.318027",
     "exception": false,
     "start_time": "2019-10-28T22:52:46.299487",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "init_op = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.020575,
     "end_time": "2019-10-28T22:52:46.351231",
     "exception": false,
     "start_time": "2019-10-28T22:52:46.330656",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def optimize(\n",
    "    training_epochs, display_step, X_train, y_train, X_test, y_test, reg_par=None\n",
    "):\n",
    "    sess.run(init_op)\n",
    "    fig = plt.figure()\n",
    "    for i in range(training_epochs):\n",
    "        if reg_par == None:  # Check if hyperparameter provided\n",
    "            sess.run([train_op, loss_op], feed_dict={X: X_train, Y: y_train})\n",
    "        else:\n",
    "            sess.run([train_op], feed_dict={X: X_train, Y: y_train, alpha: reg_par})\n",
    "\n",
    "        if i % display_step == 0:\n",
    "            # print(i)\n",
    "            pred = sess.run(R_squared, feed_dict={X: X_test, Y: y_test})\n",
    "            plt.plot(i, pred, \"bx\")\n",
    "            pred = sess.run(R_squared, feed_dict={X: X_train, Y: y_train})\n",
    "            plt.plot(i, pred, \"rx\")\n",
    "\n",
    "            # create summary\n",
    "            result = sess.run(\n",
    "                merged, feed_dict={X: X_train, Y: y_train, alpha: reg_par}\n",
    "            )\n",
    "            writer.add_summary(result, i)\n",
    "            # plt.pause(0.1)\n",
    "    print(\n",
    "        \"Finished! Accuracy of Network:\",\n",
    "        sess.run(R_squared, feed_dict={X: X_test, Y: y_test}),\n",
    "    )\n",
    "    plt.close()\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.012255,
     "end_time": "2019-10-28T22:52:46.375887",
     "exception": false,
     "start_time": "2019-10-28T22:52:46.363632",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Execute Tensorflow Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 1.772616,
     "end_time": "2019-10-28T22:52:48.162012",
     "exception": false,
     "start_time": "2019-10-28T22:52:46.389396",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    merged = tf.summary.merge_all()\n",
    "    writer = tf.summary.FileWriter(\n",
    "        \"logs/NN\", sess.graph\n",
    "    )  # for storing the neural networks\n",
    "\n",
    "    hy_par_temp = hy_par[np.random.randint(0, len(hy_par))]\n",
    "    print(\"Hyperparameter alpha: %.3f\" % hy_par_temp)\n",
    "    print(\"Training Network\")\n",
    "    optimize(\n",
    "        training_epochs,\n",
    "        display_step,\n",
    "        X_norm,\n",
    "        y_norm,\n",
    "        X_norm_test,\n",
    "        y_norm_test,\n",
    "        reg_par=hy_par_temp,\n",
    "    )\n",
    "    # saver.save(sess=sess, save_path=get_save_path(i))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
