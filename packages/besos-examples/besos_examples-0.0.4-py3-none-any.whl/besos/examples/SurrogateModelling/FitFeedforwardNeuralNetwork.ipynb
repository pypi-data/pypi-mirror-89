{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.012559,
     "end_time": "2019-10-28T22:55:02.559419",
     "exception": false,
     "start_time": "2019-10-28T22:55:02.546860",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Fit feedforward Neural Network model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2,
    "papermill": {
     "duration": 1.532357,
     "end_time": "2019-10-28T22:55:04.101770",
     "exception": false,
     "start_time": "2019-10-28T22:55:02.569413",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "import chart_studio\n",
    "from besos import eppy_funcs as ef, sampling\n",
    "from besos.evaluator import EvaluatorEP, EvaluatorGeneric\n",
    "from besos.problem import EPProblem\n",
    "from chart_studio import plotly as py\n",
    "from plotly import graph_objs as go\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from parameter_sets import parameter_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.009753,
     "end_time": "2019-10-28T22:55:04.121992",
     "exception": false,
     "start_time": "2019-10-28T22:55:04.112239",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We begin by:\n",
    "+ getting a predefined list of 7 parameters from `parameter_sets.py`\n",
    "+ making these into a `problem` with electricty use as the objective\n",
    "+ and making an `evaluator` using the default EnergyPlus building."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0,
     1,
     59,
     60
    ],
    "papermill": {
     "duration": 0.019077,
     "end_time": "2019-10-28T22:55:04.150455",
     "exception": false,
     "start_time": "2019-10-28T22:55:04.131378",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "parameters = parameter_set(7)\n",
    "problem = EPProblem(parameters, [\"Electricity:Facility\"])\n",
    "building = ef.get_building()\n",
    "evaluator = EvaluatorEP(problem, building)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.009828,
     "end_time": "2019-10-28T22:55:04.169796",
     "exception": false,
     "start_time": "2019-10-28T22:55:04.159968",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Then we get 20 samples across this design space and evaluate them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "papermill": {
     "duration": 24.293469,
     "end_time": "2019-10-28T22:55:28.473426",
     "exception": false,
     "start_time": "2019-10-28T22:55:04.179957",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "inputs = sampling.dist_sampler(sampling.lhs, problem, 20)\n",
    "outputs = evaluator.df_apply(inputs)\n",
    "inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.012864,
     "end_time": "2019-10-28T22:55:28.497525",
     "exception": false,
     "start_time": "2019-10-28T22:55:28.484661",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Train-test split\n",
    "Next we split the data into a training set (80%) and a testing set (20%)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.018578,
     "end_time": "2019-10-28T22:55:28.528683",
     "exception": false,
     "start_time": "2019-10-28T22:55:28.510105",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_in, test_in, train_out, test_out = train_test_split(\n",
    "    inputs, outputs, test_size=0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.011585,
     "end_time": "2019-10-28T22:55:28.550644",
     "exception": false,
     "start_time": "2019-10-28T22:55:28.539059",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Normalization of inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.010196,
     "end_time": "2019-10-28T22:55:28.572147",
     "exception": false,
     "start_time": "2019-10-28T22:55:28.561951",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "To ensure an equal weighting of inputs and outputs in the backpropagation algorithm fitting the neural network, we have to normalize the input values.\n",
    "For example window-to-wall ratio is in the range of 0 to 1 while the $W/$m^2$ are in a range of 10 to 15.\n",
    "Different options for normalization exist.\n",
    "Here we bring all features (input variables) to have zero mean and a standarddeviation of 1.\n",
    "Note that we fit the normalizer on training data only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.018939,
     "end_time": "2019-10-28T22:55:28.601090",
     "exception": false,
     "start_time": "2019-10-28T22:55:28.582151",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "inputs = scaler.fit_transform(X=train_in)\n",
    "\n",
    "scaler_out = StandardScaler()\n",
    "outputs = scaler_out.fit_transform(X=train_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.013102,
     "end_time": "2019-10-28T22:55:28.626264",
     "exception": false,
     "start_time": "2019-10-28T22:55:28.613162",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Hyper-parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.010562,
     "end_time": "2019-10-28T22:55:28.647533",
     "exception": false,
     "start_time": "2019-10-28T22:55:28.636971",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Before we start fitting the NN model we define the set of hyperparameters we want to analyse in our cross-validation to optimize the model.\n",
    "Here, we select the number of layers of the network as well as the regularization parameter alpha as parameter value.\n",
    "A larger number of layers and a lower value of the regularizer lead to higher variance of the network.\n",
    "This may lead to overfitting.\n",
    "The best selection may be found using an optimizer like Bayesian Optimization.\n",
    "In this example we use a simple grid search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.01634,
     "end_time": "2019-10-28T22:55:28.674195",
     "exception": false,
     "start_time": "2019-10-28T22:55:28.657855",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "hyperparameters = {\n",
    "    \"hidden_layer_sizes\": (\n",
    "        (len(parameters) * 16,),\n",
    "        (len(parameters) * 16, len(parameters) * 16),\n",
    "    ),\n",
    "    \"alpha\": [1, 10, 10 ** 3],\n",
    "}\n",
    "\n",
    "neural_net = MLPRegressor(max_iter=1000, early_stopping=False)\n",
    "folds = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.010095,
     "end_time": "2019-10-28T22:55:28.694781",
     "exception": false,
     "start_time": "2019-10-28T22:55:28.684686",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Model fitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.010223,
     "end_time": "2019-10-28T22:55:28.715272",
     "exception": false,
     "start_time": "2019-10-28T22:55:28.705049",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Here, we use the NN model from ScikitLearn.\n",
    "In a [different example](FitNNTF.ipynb) we use TensorFlow (with and without the Keras wrapper)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 5.458184,
     "end_time": "2019-10-28T22:55:34.184843",
     "exception": false,
     "start_time": "2019-10-28T22:55:28.726659",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "clf = GridSearchCV(neural_net, hyperparameters, iid=True, cv=folds)\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\", category=FutureWarning)\n",
    "    clf.fit(inputs, outputs.ravel())\n",
    "\n",
    "\n",
    "print(f\"Best performing model $R^2$ score on training set: {clf.best_score_}\")\n",
    "print(f\"Model $R^2$ parameters: {clf.best_params_}\")\n",
    "print(\n",
    "    f\"Best performing model $R^2$ score on a separate test set: {clf.best_estimator_.score(scaler.transform(test_in), scaler_out.transform(test_out))}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.010386,
     "end_time": "2019-10-28T22:55:34.205700",
     "exception": false,
     "start_time": "2019-10-28T22:55:34.195314",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Surrogate Modelling Evaluator object\n",
    "We can wrap the fitted model in a BESOS `Evaluator`.\n",
    "This has identical behaviour to the original EnergyPlus Evaluator object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.015952,
     "end_time": "2019-10-28T22:55:34.232136",
     "exception": false,
     "start_time": "2019-10-28T22:55:34.216184",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def evaluation_func(ind, scaler=scaler):\n",
    "    ind = scaler.transform(X=[ind])\n",
    "    return (scaler_out.inverse_transform(clf.predict(ind))[0],)\n",
    "\n",
    "\n",
    "NN_SM = EvaluatorGeneric(evaluation_func, problem)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.011824,
     "end_time": "2019-10-28T22:55:34.255584",
     "exception": false,
     "start_time": "2019-10-28T22:55:34.243760",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "This has identical behaviour to the original EnergyPlus Evaluator object.\n",
    "In the next cells we generate a single input sample and evaluate it using the surrogate model and EnergyPlus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.018917,
     "end_time": "2019-10-28T22:55:34.284917",
     "exception": false,
     "start_time": "2019-10-28T22:55:34.266000",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sample = sampling.dist_sampler(sampling.lhs, problem, 1)\n",
    "values = sample.values[0]\n",
    "print(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.018453,
     "end_time": "2019-10-28T22:55:34.316256",
     "exception": false,
     "start_time": "2019-10-28T22:55:34.297803",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "NN_SM(values)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 1.234111,
     "end_time": "2019-10-28T22:55:35.561773",
     "exception": false,
     "start_time": "2019-10-28T22:55:34.327662",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "evaluator(values)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.011006,
     "end_time": "2019-10-28T22:55:35.585097",
     "exception": false,
     "start_time": "2019-10-28T22:55:35.574091",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Running a large surrogate evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 1.713582,
     "end_time": "2019-10-28T22:55:37.310605",
     "exception": false,
     "start_time": "2019-10-28T22:55:35.597023",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "inputs = sampling.dist_sampler(sampling.lhs, problem, 5000)\n",
    "outputs = NN_SM.df_apply(inputs)\n",
    "results = inputs.join(outputs)\n",
    "results.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.015378,
     "end_time": "2019-10-28T22:55:37.339197",
     "exception": false,
     "start_time": "2019-10-28T22:55:37.323819",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 7.307421,
     "end_time": "2019-10-28T22:55:44.659403",
     "exception": false,
     "start_time": "2019-10-28T22:55:37.351982",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "chart_studio.tools.set_credentials_file(\n",
    "    username=\"besos\", api_key=\"Kb2G2bjOh5gmwh1Midwq\"\n",
    ")\n",
    "df = inputs.round(3)\n",
    "\n",
    "# generate list if dictionaries\n",
    "l = list()\n",
    "for i in df.columns:\n",
    "    l.extend([dict(label=i, values=df[i])])\n",
    "\n",
    "l.extend([dict(label=outputs.columns[0], values=outputs.round(-5))])\n",
    "\n",
    "data = [\n",
    "    go.Parcoords(\n",
    "        line=dict(\n",
    "            color=outputs[\"Electricity:Facility\"],\n",
    "            colorscale=[[0, \"#D7C16B\"], [0.5, \"#23D8C3\"], [1, \"#F3F10F\"]],\n",
    "        ),\n",
    "        dimensions=l,\n",
    "    )\n",
    "]\n",
    "\n",
    "layout = go.Layout(plot_bgcolor=\"#E5E5E5\", paper_bgcolor=\"#E5E5E5\")\n",
    "\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "py.iplot(fig, filename=\"parcoords-basic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.029959,
     "end_time": "2019-10-28T22:55:44.728157",
     "exception": false,
     "start_time": "2019-10-28T22:55:44.698198",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
